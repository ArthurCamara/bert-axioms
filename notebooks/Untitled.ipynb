{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T13:00:03.471512Z",
     "start_time": "2019-08-23T13:00:03.446421Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T13:01:04.277748Z",
     "start_time": "2019-08-23T13:01:04.251546Z"
    }
   },
   "outputs": [],
   "source": [
    "from msmarco_dataset import MsMarcoDataset\n",
    "from args_parser import getArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T13:02:18.304768Z",
     "start_time": "2019-08-23T13:02:18.276307Z"
    }
   },
   "outputs": [],
   "source": [
    "argv = [\"--data_dir\", \"/ssd2/arthur/TREC2019/data\", \n",
    "        \"--train_file\", \"/ssd2/arthur/insy/msmarco/data/train-triples.1\",\n",
    "        \"--dev_file\", \"/ssd2/arthur/insy/msmarco/data/dev-triples.1\",\n",
    "        \"--bert-model\", \"bert-base-uncased\"]\n",
    "args = getArgs(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T13:03:37.503685Z",
     "start_time": "2019-08-23T13:02:32.464807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7969472558d1405094d17c6051fce061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing offset dictionary', max=573454, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbdd20397d544147a558c6be8d30c80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing offset dictionary', max=8114, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = MsMarcoDataset(args.train_file, args.data_dir)\n",
    "dev_dataset  = MsMarcoDataset(args.dev_file, args.data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T13:04:47.472443Z",
     "start_time": "2019-08-23T13:04:47.427395Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_level_classifier import fine_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:27:50.051779Z",
     "start_time": "2019-08-19T13:27:49.959628Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T12:58:21.332264Z",
     "start_time": "2019-08-19T12:58:21.302712Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
    "def init_optimizer(\n",
    "        model: BertForNextSentencePrediction,\n",
    "        n_steps, lr,\n",
    "        warmup_proportion=0.1,\n",
    "        weight_decay=0.0):\n",
    "\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(\n",
    "            nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(\n",
    "            nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=1e-8)\n",
    "    warmup_steps = n_steps * warmup_proportion\n",
    "    scheduler = WarmupLinearSchedule(\n",
    "        optimizer, warmup_steps=warmup_steps, t_total=n_steps)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:24:16.881665Z",
     "start_time": "2019-08-19T13:24:09.288081Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/miniconda3/envs/bert/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:72: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_transformers import BertForNextSentencePrediction\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model = BertForNextSentencePrediction.from_pretrained(args.bert_model)\n",
    "data_loader = DataLoader(dataset, args.batch_size, shuffle=True)\n",
    "\n",
    "num_train_optimization_steps = len(data_loader) // args.n_epochs\n",
    "optimizer, scheduler = init_optimizer(model, num_train_optimization_steps, args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:32:11.247508Z",
     "start_time": "2019-08-19T13:31:23.849937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bacd283bd1c4e3d8413610491a1bfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=3, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fc63b9fc0242798639f6dfb3a5b0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Batches', max=1, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/miniconda3/envs/bert/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:72: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "tr_loss = 0\n",
    "global_step = 0\n",
    "\n",
    "for _ in tqdm(range(args.n_epochs), desc=\"Epochs\"):\n",
    "    for step, batch in tqdm(enumerate(data_loader), desc=\"Batches\"):\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'token_type_ids': batch[2],\n",
    "            'next_sentence_label': batch[3]}\n",
    "        # forward propagation\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0].mean()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "        tr_loss += loss.item()\n",
    "        \n",
    "        if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "            scheduler.step()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            global_step += 1\n",
    "        break\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:25:57.054374Z",
     "start_time": "2019-08-19T13:25:38.141953Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:26:17.345684Z",
     "start_time": "2019-08-19T13:26:17.321354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.8139, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:26:02.446101Z",
     "start_time": "2019-08-19T13:26:02.319844Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = outputs[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:18:24.496485Z",
     "start_time": "2019-08-19T13:18:24.394068Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_eval_loss, logits = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T14:01:49.131753Z",
     "start_time": "2019-08-16T14:01:49.109194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f27a5100b00>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T14:03:41.043899Z",
     "start_time": "2019-08-16T14:03:25.759482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd2d8e382fa4891b71bb017cf7fa036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_loss = 0.0\n",
    "nb_eval_steps = 0\n",
    "preds = None\n",
    "out_label_ids = None\n",
    "for batch in tqdm(eval_dataloader):\n",
    "    if 0 in batch[3]:\n",
    "        breake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T14:03:09.513350Z",
     "start_time": "2019-08-16T14:03:09.491378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 in batch[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
