{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:01:39.350510Z",
     "start_time": "2019-09-02T15:01:38.668274Z"
    }
   },
   "outputs": [],
   "source": [
    "import pytorch_transformers\n",
    "import sys\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(0, \"/ssd2/arthur/TREC2019/scripts/\")\n",
    "from msmarco_dataset import MsMarcoDataset\n",
    "from args_parser import getArgs\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.autonotebook import tqdm\n",
    "from pytorch_transformers import AdamW, WarmupLinearSchedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:01:39.470427Z",
     "start_time": "2019-09-02T15:01:39.353951Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'is_distil' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-33ba82e6972a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mis_distil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'is_distil' is not defined"
     ]
    }
   ],
   "source": [
    "is_distil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:01:44.923408Z",
     "start_time": "2019-09-02T15:01:44.891686Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"/ssd2/arthur/TREC2019/data/\"\n",
    "argv = [\n",
    "    \"--data_dir\", data_dir,\n",
    "    \"--train_file\", data_dir + \"/train-triples.0\",\n",
    "    \"--dev_file\", data_dir + \"/dev-triples.0\",\n",
    "    \"--per_gpu_train_batch_size\", \"8\",\n",
    "    \"--train_batch_size\", \"32\",\n",
    "    \"--gradient_accumulation_steps\", \"10\",\n",
    "    \"--ignore_gpu_ids\", \"0,1,2,5,6\",\n",
    "    \"--limit_gpus\", \"-1\",\n",
    "    \"--eval_steps\", \"10\",\n",
    "    \"--bert_model\", \"distilbert-base-uncased\"\n",
    "]\n",
    "args = getArgs(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:01:45.700427Z",
     "start_time": "2019-09-02T15:01:45.678122Z"
    }
   },
   "outputs": [],
   "source": [
    "is_distil = \"distilbert\" in args.bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:02:07.390699Z",
     "start_time": "2019-09-02T15:02:07.366867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not is_distil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:41:29.238322Z",
     "start_time": "2019-09-02T14:41:25.440429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f75e173abb41fd97130814d1d5e1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Counting lines on file...', max=1, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b815f2ee654b1ca0f4fc3fee364d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Counting lines on file...', max=1, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MsMarcoDataset(args.train_file, args.data_dir, invert_label=False, distil=True)\n",
    "dev_dataset = MsMarcoDataset(args.dev_file, args.data_dir, invert_label=False, distil=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:41:36.631203Z",
     "start_time": "2019-09-02T14:41:30.018756Z"
    }
   },
   "outputs": [],
   "source": [
    "model = pytorch_transformers.DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:41:37.394782Z",
     "start_time": "2019-09-02T14:41:37.377902Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_dataset, batch_size=args.train_batch_size, shuffle=True)\n",
    "dev_data_loader = DataLoader(dev_dataset, batch_size = args.eval_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:41:42.833025Z",
     "start_time": "2019-09-02T14:41:39.391110Z"
    }
   },
   "outputs": [],
   "source": [
    "n_gpu = 0\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "    # We DO NOT want to limit the number of GPUs to be used\n",
    "    if args.limit_gpus < 0:\n",
    "        args.limit_gpus = torch.cuda.device_count()\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "    # We WANT to limit the number of GPUs to be used\n",
    "    else:\n",
    "        n_gpu = min(torch.cuda.device_count(), args.limit_gpus)\n",
    "\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()\n",
    "                                 and n_gpu > 0 and args.limit_gpus != 1) else \"cpu\")\n",
    "if n_gpu > 0:\n",
    "    gpu_ids = list(range(n_gpu))\n",
    "    # Ignore any GPU? (usefull if there is more users on current machine, already using a GPU)\n",
    "    if args.ignore_gpu_ids is not None:\n",
    "        for _id in args.ignore_gpu_ids:\n",
    "            if _id in gpu_ids:\n",
    "                gpu_ids.remove(_id)\n",
    "    model = torch.nn.DataParallel(model, device_ids=gpu_ids)\n",
    "if n_gpu > 0:\n",
    "    device_0 = torch.device(\"cuda:{}\" .format(gpu_ids[0]))\n",
    "    model.to(device_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:41:43.980566Z",
     "start_time": "2019-09-02T14:41:43.958972Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/miniconda3/envs/bert/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:72: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "warmup_proportion=0.1\n",
    "weight_decay=0.0\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "lr = args.learning_rate\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(\n",
    "        nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(\n",
    "        nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "num_train_optimization_steps = len(train_data_loader) // args.gradient_accumulation_steps * args.n_epochs\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=1e-8)\n",
    "warmup_steps = num_train_optimization_steps * warmup_proportion\n",
    "scheduler = WarmupLinearSchedule(\n",
    "    optimizer, warmup_steps=warmup_steps, t_total=num_train_optimization_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:42:04.732385Z",
     "start_time": "2019-09-02T14:41:50.484519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06181540c0a4f1a965bfaee2690292d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Batches', max=1, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/miniconda3/envs/bert/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "tr_loss = 0.0\n",
    "for step, batch in tqdm(enumerate(train_data_loader), desc=\"Batches\"):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    inputs = {'input_ids': batch[0],\n",
    "          'attention_mask': batch[1],\n",
    "          'labels': batch[3]}\n",
    "    model.train()\n",
    "    outputs = model(**inputs)\n",
    "    loss = outputs[0]\n",
    "    if len(loss) > 1:\n",
    "        loss = loss.mean()\n",
    "    if args.gradient_accumulation_steps > 1:\n",
    "        loss = loss / args.gradient_accumulation_steps\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    loss.backward()\n",
    "    tr_loss += loss.item()\n",
    "    if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        model.zero_grad()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:44:28.123979Z",
     "start_time": "2019-09-02T14:44:28.097585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pytorch_transformers.modeling_distilbert.DistilBertForSequenceClassification"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:44:51.944802Z",
     "start_time": "2019-09-02T14:44:51.702814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10f6aaf81384a93b701839551b85964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=64), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_loss = 0\n",
    "preds = None\n",
    "out_label_ids = None\n",
    "for batch in tqdm(dev_data_loader):\n",
    "    model.eval()\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    break\n",
    "#     with torch.no_grad():\n",
    "#         if model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:46:16.420675Z",
     "start_time": "2019-09-02T14:46:16.406739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issubclass(type(model.module), pytorch_transformers.DistilBertModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:47:48.397527Z",
     "start_time": "2019-09-02T14:47:48.249910Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/miniconda3/envs/bert/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    if isinstance(model.module, pytorch_transformers.DistilBertForSequenceClassification):\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[3]}\n",
    "    else:\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'token_type_ids': batch[2],\n",
    "                  'next_sentence_label': batch[3]}\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:53:17.095315Z",
     "start_time": "2019-09-02T14:53:17.058738Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_loss = 0.0\n",
    "tmp_eval_loss, logits = outputs[:2]\n",
    "eval_loss += tmp_eval_loss.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:55:35.772846Z",
     "start_time": "2019-09-02T14:55:35.737569Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, average_precision_score, accuracy_score\n",
    "\n",
    "preds = logits.detach().cpu().numpy()\n",
    "out_label_ids = inputs['labels'].detach().cpu().numpy().flatten()\n",
    "preds = np.argmax(preds, axis=1)\n",
    "assert len(preds) == len(out_label_ids)\n",
    "\n",
    "result = {}\n",
    "result[\"acc\"] = accuracy_score(out_label_ids, preds)\n",
    "result[\"f1\"] = f1_score(out_label_ids, preds)\n",
    "result[\"AP\"] = average_precision_score(out_label_ids, preds)\n",
    "result[\"acc_and_f1\"] = (result[\"acc\"] + result[\"f1\"]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:55:38.356021Z",
     "start_time": "2019-09-02T14:55:38.337215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.0078125,\n",
       " 'f1': 0.015503875968992248,\n",
       " 'AP': 0.0078125,\n",
       " 'acc_and_f1': 0.011658187984496124}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:56:08.316310Z",
     "start_time": "2019-09-02T14:56:08.287677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:25:49.940260Z",
     "start_time": "2019-09-02T14:25:48.927863Z"
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "output = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:27:51.610527Z",
     "start_time": "2019-09-02T14:27:51.580412Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = output[0]\n",
    "if len(loss) > 1:\n",
    "    loss = loss.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T14:27:53.455122Z",
     "start_time": "2019-09-02T14:27:53.436355Z"
    }
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
