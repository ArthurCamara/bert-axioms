{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T10:55:53.587686Z",
     "start_time": "2019-10-11T10:55:53.074914Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T10:55:54.532336Z",
     "start_time": "2019-10-11T10:55:54.511508Z"
    }
   },
   "outputs": [],
   "source": [
    "axioms = [\"TFC1\", \"TFC2\", \"MTDC\", \"LNC1\", \"LNC2\", \"TPC\", \"STMC1\", \"STMC2\", \"STMC3\", \"LB1\", \"LB2\"]\n",
    "axioms = [\"TPC\"]\n",
    "axioms_with_custom_run_files = set([\"LNC2\", \"LB1\", \"LB2\"])\n",
    "data_home = \"/ssd2/arthur/TREC2019/data/\"\n",
    "qrels_path = os.path.join(data_home, 'qrels', \"test_qrels\")\n",
    "qrels = {}\n",
    "for line in open(qrels_path):\n",
    "    topic_id, _, doc_id, rel = line.split(\"\\t\")\n",
    "    if topic_id in qrels:\n",
    "        qrels[topic_id].append(doc_id)\n",
    "    else:\n",
    "        qrels[topic_id] = [doc_id]\n",
    "instances_path = os.path.join(data_home, \"diagnostics\")\n",
    "paths = {}\n",
    "assert os.path.isdir(instances_path)\n",
    "for ax in axioms:\n",
    "    if not os.path.isfile(instances_path+\"/{}-instances\".format(ax)):\n",
    "        print(\"Instances file for axiom {} is missing\".format(ax))\n",
    "    else:\n",
    "        paths[ax] = instances_path+\"/{}-instances\".format(ax)\n",
    "        \n",
    "run_files = {\n",
    "        \"QL\": os.path.join(data_home, 'runs', \"test_distilBert-0.0.run\"),\n",
    "        \"BERT\": os.path.join(data_home, 'runs', \"test_distilBert-1.0.run\"),\n",
    "#         \"QL+BERT\": os.path.join(data_home, 'runs', \"test_distilBert-0.85.run\")\n",
    "}\n",
    "scores = dict.fromkeys(run_files.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T10:56:00.534706Z",
     "start_time": "2019-10-11T10:55:57.904603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPC\n",
      "\t 3010246 19666 3572 0.1816\n"
     ]
    }
   ],
   "source": [
    "for ax in axioms:\n",
    "    print(ax)\n",
    "    instances = pickle.load(open(paths[ax], 'rb'))\n",
    "    instances_with_relevant = 0\n",
    "    instances_with_right_ordering = 0\n",
    "    if len(instances[0]) == 4:\n",
    "        for topic_id, di, dj, dk in instances:\n",
    "            topic_id = topic_id.split(\"-\")[0]\n",
    "            if di in qrels[topic_id] or dj in qrels[topic_id] or dk in qrels[topic_id]:\n",
    "                instances_with_relevant += 1\n",
    "                di_score = dj_score = dk_score = 0\n",
    "                if di in qrels[topic_id]:\n",
    "                    di_score = 1\n",
    "                if dj in qrels[topic_id]:\n",
    "                    dj_score = 1\n",
    "                if dk in qrels[topic_id]:\n",
    "                    dk_score = 1\n",
    "                if dj_score - di_score > dk_score - dj_score:\n",
    "                    instances_with_right_ordering += 1\n",
    "        print(\"\\t\",len(instances), instances_with_relevant, instances_with_right_ordering, \"{:.4f}\".format(instances_with_right_ordering/instances_with_relevant))\n",
    "        continue\n",
    "    for topic_id, di, dj in instances:\n",
    "        _topic_id = topic_id.split(\"-\")[0] # This is needed in some cases with custom topic ids. \n",
    "        _di = di.split(\"-\")[0] # This is needed for LB2 modified doc_ids\n",
    "        _dj = dj.split(\"-\")[0] # This is needed for LB2, for instance\n",
    "        if _di in qrels[_topic_id] or _dj in qrels[_topic_id]:\n",
    "            instances_with_relevant += 1\n",
    "            if _di in qrels[_topic_id]:\n",
    "                instances_with_right_ordering+=1\n",
    "    print(\"\\t\",len(instances), instances_with_relevant, instances_with_right_ordering, \"{:.4f}\".format(instances_with_right_ordering/instances_with_relevant))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T10:57:21.750725Z",
     "start_time": "2019-10-11T10:57:19.802635Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_transformers import BertTokenizer\n",
    "queries_file = \"queries/test_queries.tsv\"\n",
    "queries_file = os.path.join(data_home, queries_file)\n",
    "assert os.path.isfile(queries_file)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "queries = {}\n",
    "for line in open  (queries_file):\n",
    "    q_id, query_text = line.strip().split(\"\\t\")\n",
    "    tokenized_query = tokenizer.tokenize(query_text)\n",
    "    queries[q_id] = tokenized_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T10:57:45.622858Z",
     "start_time": "2019-10-11T10:57:34.135090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\n",
      "\t TPC 3010246\n",
      "\t\tQL 3010246 1325074 0.44\n",
      "\t\tBERT 3010246 1365750 0.45\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "results = []\n",
    "relevants = False\n",
    "# axioms = [\"LB1\"]\n",
    "# splits = [(\"short\", first_percentile), (\"medium\", second_percentile), (\"long\", last_percentile)]\n",
    "for name, topic_to_use in [(\"all\", queries.keys())]:\n",
    "    print(name)\n",
    "    for ax in axioms:\n",
    "        instances = pickle.load(open(paths[ax], 'rb'))\n",
    "        instances = [x for x in instances if x[0] in topic_to_use or ax==\"LB1\"]\n",
    "        print(\"\\t\",ax, len(instances))\n",
    "        for method in run_files:\n",
    "            scores[method] = {}\n",
    "            if ax in axioms_with_custom_run_files:\n",
    "                run_file_path = run_files[method].replace(\"test\", ax)\n",
    "                print(run_file_path)\n",
    "            else:\n",
    "                run_file_path = run_files[method]\n",
    "            if ax == \"LNC2\":\n",
    "                run_file_path = run_file_path.replace(\"LNC2\", \"LNC2_dev\")\n",
    "            for line in open(run_file_path):\n",
    "                topic_id, _, doc_id, _, score, _ = line.split()\n",
    "                pair_id = \"{}-{}\".format(topic_id, doc_id)\n",
    "                scores[method][pair_id] = float(score)\n",
    "            instances_with_relevant = 0\n",
    "            instances_with_right_ordering = 0\n",
    "            if len(instances) == 0:\n",
    "                print(\"\\t\\t{}\".format(method), 0, 0, \"{:.4f}\".format(0))\n",
    "                continue\n",
    "            if len(instances[0]) == 4:\n",
    "                for topic_id, di, dj, dk in instances:\n",
    "                    topic_id = topic_id.split(\"-\")[0]\n",
    "                    # This is TFC2\n",
    "                    if (di in qrels[topic_id] or dj in qrels[topic_id] or dk in qrels[topic_id]) or not relevants:\n",
    "                        instances_with_relevant += 1\n",
    "                        di_score = scores[method][\"{}-{}\".format(topic_id, di)]\n",
    "                        dj_score = scores[method][\"{}-{}\".format(topic_id, dj)]\n",
    "                        dk_score = scores[method][\"{}-{}\".format(topic_id, dk)]\n",
    "                        if dj_score - di_score > dk_score-dj_score:\n",
    "                            instances_with_right_ordering += 1\n",
    "                results.append({\"method\":method, \"dataset\": ax+\"-\"+name, \"value\": instances_with_right_ordering/instances_with_relevant})\n",
    "                print(\"\\t\\t{}\".format(method), instances_with_relevant, instances_with_right_ordering, \"{:.4f}\".format(instances_with_right_ordering/instances_with_relevant))\n",
    "                continue\n",
    "            for topic_id, di, dj in instances:\n",
    "                _topic_id = topic_id.split(\"-\")[0] # This is needed in some cases with custom topic ids. \n",
    "                _di = di.split(\"-\")[0] # This is needed for LB2 modified doc_ids\n",
    "                _dj = dj.split(\"-\")[0] # This is needed for LB2, for instance\n",
    "                if (_di in qrels[_topic_id] or _dj in qrels[_topic_id]) or not relevants:\n",
    "                    instances_with_relevant += 1\n",
    "                    di_score = scores[method][\"{}-{}\".format(topic_id, di)]\n",
    "                    dj_score = scores[method][\"{}-{}\".format(topic_id, dj)]\n",
    "                    if ax == \"LNC1\" or ax==\"STMC2\" or ax==\"LB1\":\n",
    "                        if di_score >= dj_score and (_di in qrels[_topic_id] or not relevants):\n",
    "                            instances_with_right_ordering += 1\n",
    "                    elif ax==\"STMC3\":\n",
    "                        if di_score <= dj_score and (_di in qrels[_topic_id] or not relevants):\n",
    "                            instances_with_right_ordering += 1\n",
    "                    else:\n",
    "                        if di_score > dj_score and (_di in qrels[_topic_id] or not relevants):\n",
    "                            instances_with_right_ordering += 1\n",
    "            results.append({\"method\":method, \"dataset\": ax+\"-\"+name, \"value\": instances_with_right_ordering/instances_with_relevant})\n",
    "            print(\"\\t\\t{}\".format(method), instances_with_relevant, instances_with_right_ordering, \"{:.2f}\".format(instances_with_right_ordering/instances_with_relevant))\n",
    "df = pd.DataFrame(results)\n",
    "df.pivot(\"dataset\", \"method\",  \"value\").to_csv(\"query_stopwords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T12:28:42.290339Z",
     "start_time": "2019-10-08T12:28:42.287559Z"
    }
   },
   "outputs": [],
   "source": [
    "all_questions = list(queries.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T00:30:18.253809Z",
     "start_time": "2019-10-09T00:30:18.242578Z"
    }
   },
   "outputs": [],
   "source": [
    "lens = [len(x) for x in all_questions]\n",
    "relevant_docs = \n",
    "# import numpy as np\n",
    "np.mean(lens)\n",
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "sw_counter = [sum([1 if x in sw else 0 for x in y]) for y in all_questions ]\n",
    "# sw_counter = [sum(x) for x in sw_masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T00:30:21.666384Z",
     "start_time": "2019-10-09T00:30:21.657381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 3.0, 12.0)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(sw_counter, 100/3), np.percentile(sw_counter, 200/3), np.percentile(sw_counter, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T00:32:05.319295Z",
     "start_time": "2019-10-09T00:32:04.561445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(755, 385, 418)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_percentile = []\n",
    "second_percentile = []\n",
    "last_percentile = []\n",
    "for q in queries:\n",
    "    if sum([1 if x in sw else 0 for x in queries[q]]) < np.percentile(sw_counter, 100/3):\n",
    "        first_percentile.append(q)\n",
    "    elif sum([1 if x in sw else 0 for x in queries[q]]) < np.percentile(sw_counter, 200/3):\n",
    "        second_percentile.append(q)\n",
    "    else:\n",
    "        last_percentile.append(q)\n",
    "len(last_percentile), len(first_percentile), len(second_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T09:21:45.552109Z",
     "start_time": "2019-10-11T09:21:45.544781Z"
    }
   },
   "outputs": [],
   "source": [
    "def getcontent(docid, file_name):\n",
    "    \"\"\"getcontent(docid, f) will get content for a given docid (a string) from filehandle f.\n",
    "    The content has four tab-separated strings: docid, url, title, body.\n",
    "    \"\"\"\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        f.seek(docoffset[docid])\n",
    "        line = f.readline()\n",
    "        assert line.startswith(docid + \"\\t\"), f\"Looking for {docid}, found {line}\"\n",
    "    return line.rstrip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T09:21:47.519077Z",
     "start_time": "2019-10-11T09:21:46.314912Z"
    }
   },
   "outputs": [],
   "source": [
    "lookup_file = \"/ssd2/arthur/TREC2019/data/docs/tokenized-msmarco-docs.tsv.offset\"\n",
    "docs_file = \"/ssd2/arthur/TREC2019/data/docs/tokenized-msmarco-docs.tsv\"\n",
    "number_of_lines_to_process = 3213835\n",
    "\n",
    "docoffset = pickle.load(open(lookup_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T09:30:40.124191Z",
     "start_time": "2019-10-11T09:30:39.950059Z"
    }
   },
   "outputs": [],
   "source": [
    "full_run_file = \"/ssd2/arthur/TREC2019/data/runs/test_distilBert-{}.run\".format(0.0)\n",
    "viable_topics = set()\n",
    "for line in open(full_run_file):\n",
    "    topic_id, _, doc_id, _, _, _ = line.split()\n",
    "#     if doc_id == qrels[topic_id][0]:\n",
    "    viable_topics.add(topic_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T09:30:43.536168Z",
     "start_time": "2019-10-11T09:30:43.204411Z"
    }
   },
   "outputs": [],
   "source": [
    "overlaps = dict()\n",
    "\n",
    "for q in queries:\n",
    "    if q not in viable_topics:\n",
    "        continue\n",
    "    relevant = set(getcontent(qrels[q][0], docs_file).split(\"\\t\")[1].split())\n",
    "    overlap = len(set(queries[q]).intersection(relevant))/len(set(queries[q]))\n",
    "    overlaps[q] = overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T09:30:46.041671Z",
     "start_time": "2019-10-11T09:30:45.389173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456 565 537\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "first_percentile = []\n",
    "second_percentile = []\n",
    "last_percentile = []\n",
    "for q in queries:\n",
    "    if q not in viable_topics:\n",
    "        continue\n",
    "    if overlaps[q] < np.percentile(list(overlaps.values()), 100/3):\n",
    "        first_percentile.append(q)\n",
    "    elif overlaps[q] < np.percentile(list(overlaps.values()), 200/3):\n",
    "        second_percentile.append(q)\n",
    "    else:\n",
    "        last_percentile.append(q)\n",
    "print(len(first_percentile), len(second_percentile), len(last_percentile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T09:31:13.030971Z",
     "start_time": "2019-10-11T09:31:13.021920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.75)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(list(overlaps.values()), 100/3), np.percentile(list(overlaps.values()), 200/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T09:31:40.323196Z",
     "start_time": "2019-10-11T09:31:33.078070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[0.0, 0.5)\n",
      "\talpha: 0.0\t ndcg: 0.0176\n",
      "[.5, .75)\n",
      "\talpha: 0.0\t ndcg: 0.1627\n",
      "[.75, 1.0]\n",
      "\talpha: 0.0\t ndcg: 0.4462\n",
      "1.0\n",
      "[0.0, 0.5)\n",
      "\talpha: 1.0\t ndcg: 0.0419\n",
      "[.5, .75)\n",
      "\talpha: 1.0\t ndcg: 0.2739\n",
      "[.75, 1.0]\n",
      "\talpha: 1.0\t ndcg: 0.4933\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "trec_eval_path = \"/ssd2/arthur/trec_eval/trec_eval\"\n",
    "ndcg_cmd = \"{} -q -m ndcg {} {}\"\n",
    "results = []\n",
    "for alpha in [0.0, 1.0]:\n",
    "    print(alpha)\n",
    "    for counter,( name, split) in enumerate([(\"[0.0, 0.5)\", first_percentile), (\"[.5, .75)\", second_percentile), (\"[.75, 1.0]\", last_percentile)]):\n",
    "        print(name)\n",
    "        full_run_file = \"/ssd2/arthur/TREC2019/data/runs/test_distilBert-{}.run\".format(alpha)\n",
    "        out_run_file = \"/ssd2/arthur/TREC2019/data/runs/{}_test_distilBert-{}.run\".format(counter, alpha)\n",
    "        with open(out_run_file, \"w\") as outf:\n",
    "            for line in open(full_run_file):\n",
    "                topic_id = line.split()[0]\n",
    "                if topic_id in split:\n",
    "                    outf.write(line)\n",
    "        ndcgs = subprocess.check_output(ndcg_cmd.format(trec_eval_path, qrels_path, out_run_file).split()).decode('utf-8')\n",
    "        _ndcg = ndcgs.split(\"\\n\")[-2].split(\"\\t\")[-1]\n",
    "        print(\"\\talpha: {}\\t ndcg: {}\".format(alpha, _ndcg))\n",
    "        if alpha == 0.0: method = \"QL\" \n",
    "        if alpha == 1.0: method = \"BERT\" \n",
    "        if alpha == 0.85: method = \"QL+BERT\" \n",
    "        results.append({\"method\":method, \"dataset\": name, \"value\": _ndcg, \"len\":len(split)})\n",
    "df = pd.DataFrame(results)\n",
    "df.pivot(\"dataset\", \"method\",  \"value\").to_csv(\"term_overlap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:35:49.390287Z",
     "start_time": "2019-10-09T12:35:49.375561Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T13:28:46.530772Z",
     "start_time": "2019-10-09T13:28:46.514504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>value</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>QL</td>\n",
       "      <td>[0.0, 0.5)</td>\n",
       "      <td>0.0448</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>QL</td>\n",
       "      <td>[.5, .75)</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>QL</td>\n",
       "      <td>[.75, 1.0]</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>BERT</td>\n",
       "      <td>[0.0, 0.5)</td>\n",
       "      <td>0.0905</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BERT</td>\n",
       "      <td>[.5, .75)</td>\n",
       "      <td>0.3066</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>BERT</td>\n",
       "      <td>[.75, 1.0]</td>\n",
       "      <td>0.5334</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method     dataset   value  len\n",
       "0     QL  [0.0, 0.5)  0.0448  616\n",
       "1     QL   [.5, .75)  0.2095  485\n",
       "2     QL  [.75, 1.0]  0.4719  457\n",
       "3   BERT  [0.0, 0.5)  0.0905  616\n",
       "4   BERT   [.5, .75)  0.3066  485\n",
       "5   BERT  [.75, 1.0]  0.5334  457"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
