{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:06:04.655553Z",
     "start_time": "2019-07-15T11:06:03.601036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "from tqdm import tnrange as trange\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from pytorch_pretrained_bert.file_utils import WEIGHTS_NAME, CONFIG_NAME\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
    "logger = logging.getLogger(__name__)\n",
    "import sys\n",
    "import csv\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:08:33.609619Z",
     "start_time": "2019-07-15T11:08:33.602199Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"/ssd2/arthur/TREC2019/data/\"\n",
    "bert_model=\"bert-base-uncased\"\n",
    "output_dir = \"/ssd2/arthur/TREC2019/data/bert-output/\"\n",
    "max_seq_len=512\n",
    "local_rank = -1\n",
    "device = torch.device('cuda')\n",
    "n_gpu = 2\n",
    "train_batch_size = 32\n",
    "task_name = \"msmarco_2\"\n",
    "num_train_epochs = 1\n",
    "learning_rate = 5e-5\n",
    "warmup_proportion = 0.1\n",
    "eval_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:07:44.633931Z",
     "start_time": "2019-07-15T11:07:44.622999Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:07:38.328397Z",
     "start_time": "2019-07-15T11:07:38.282519Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class InputExample:\n",
    "    def __init__(self, guid, text_a, text_b, label):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "class InputFeatures(object):\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "\n",
    "class Processor():\n",
    "    def _read_tsv(self, input_file):\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f, delimiter = '\\t')\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                lines.append(line)\n",
    "                if len(lines) > 10000:\n",
    "                    return lines\n",
    "            return lines\n",
    "    \n",
    "    def get_train_examples(self, data_dir):\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train-samples.tsv\")), \"train\")\n",
    "    \n",
    "    def get_dev_examples(self, data_dir):\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev-samples.tsv\")), \"dev\")\n",
    "    \n",
    "    def _create_examples(self, lines, set_type):\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            try:\n",
    "                guid = \"%s-%s\" % (set_type, line[0])\n",
    "                query = line[1]\n",
    "                doc = line[2]\n",
    "                label = line[-1]\n",
    "                examples.append(InputExample(guid=guid, text_a=query, text_b=doc, label=label))\n",
    "            except:\n",
    "                print(i, line)\n",
    "                continue\n",
    "        return examples\n",
    "processor = Processor()\n",
    "output_mode = \"classification\"\n",
    "label_list = ['1','0']\n",
    "num_labels = 2\n",
    "\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, output_mode):\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "    features= []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "        tokens_b = tokenizer.tokenize(example.text_b)\n",
    "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "        tokens = [\"[CLS]\"] + tokens_a +[\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "        \n",
    "        segment_ids = [0] * (len(tokens_a) +2)\n",
    "        segment_ids += [1] * (len(tokens_b) +1)\n",
    "        \n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "        \n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        \n",
    "        if output_mode == \"classification\":\n",
    "            label_id = label_map[example.label]\n",
    "        elif output_mode == \"regression\":\n",
    "            label_id = float(example.label)\n",
    "        else:\n",
    "            raise KeyError(output_mode)\n",
    "        \n",
    "        if ex_index < 1:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"guid: %s\" % (example.guid))\n",
    "            logger.info(\"tokens: %s\" % \" \".join(\n",
    "                    [str(x) for x in tokens]))\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "            logger.info(\n",
    "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "            logger.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id))\n",
    "    return features\n",
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "def compute_metrics(task_name, preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return {\"acc\": simple_accuracy(preds, labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:08:10.752939Z",
     "start_time": "2019-07-15T11:07:48.737235Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=True)\n",
    "model = BertForSequenceClassification.from_pretrained(bert_model, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:08:17.994675Z",
     "start_time": "2019-07-15T11:08:10.757540Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:14:25.500760Z",
     "start_time": "2019-07-15T11:08:38.465763Z"
    }
   },
   "outputs": [],
   "source": [
    "global_step = 0 \n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0\n",
    "tb_writter = SummaryWriter()\n",
    "train_examples = processor.get_train_examples(data_dir)\n",
    "\n",
    "#Preprocess inputs as input_ids (tokens ids), input_mask (for masking trainning), segment_id (id for first and second segment) and label_id\n",
    "cached_train_features_file = os.path.join(data_dir, 'train_{}_{}_{}'.format(list(filter(None, bert_model.split('/'))).pop(), str(max_seq_len), str(task_name)))\n",
    "try:\n",
    "    with open(cached_train_features_file, \"rb\") as reader:\n",
    "        train_features = pickle.load(reader)\n",
    "except:\n",
    "    train_features = convert_examples_to_features(train_examples, label_list, max_seq_len, tokenizer, output_mode)\n",
    "    with open(cached_train_features_file, \"wb\") as writer:\n",
    "        pickle.dump(train_features, writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:15:34.296753Z",
     "start_time": "2019-07-15T11:15:31.944624Z"
    }
   },
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:15:41.301758Z",
     "start_time": "2019-07-15T11:15:41.270485Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids) #loader for datasets, will yield one sample at a time\n",
    "train_sampler = RandomSampler(train_data) #randomly pick one sample\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size = train_batch_size) #join both as a single loader\n",
    "num_train_optimization_steps = len(train_dataloader) *3 #number of optimization rounds to be completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:15:43.580471Z",
     "start_time": "2019-07-15T11:15:43.568102Z"
    }
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters()) #params to be optimized\n",
    "no_decay =['bias', 'LayerNorm.bias', 'LayerNorm.weight'] #params that the learning rate should not be decayed over training steps\n",
    "optimizer_grouped_params = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay':0.01}, #rate do decay params\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay':0.0}] #params that shoud not decay\n",
    "optimizer = BertAdam(optimizer_grouped_params, lr=learning_rate, warmup=warmup_proportion, t_total =num_train_optimization_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T11:21:14.337240Z",
     "start_time": "2019-07-15T11:15:47.409804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6857b303a4442a92a43531b20a5bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc622a237d142a080a06ebd915e052a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=313, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for _ in trange(int(num_train_epochs), desc=\"Epoch\"): #for each epoch\n",
    "    tr_loss = 0 #training loss for this epoch\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch) #send this batch to gpu. Each size of batch is [batch_size, max_tokens]. Labels is just [batch_size]\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "        \n",
    "        logits = model(input_ids, token_type_ids=segment_ids, attention_mask = input_mask) #model output. sized [batch_size, n_classes]\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "        loss = loss.mean() #average over all gpus\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples+=input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        global_step +=1\n",
    "        tb_writter.add_scalar('lr', optimizer.get_lr()[0], global_step)\n",
    "        tb_writter.add_scalar('loss', loss.item(), global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T19:40:53.545156Z",
     "start_time": "2019-07-14T19:40:51.094469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ssd2/arthur/TREC2019/data/bert-output/vocab.txt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "tokenizer.save_vocabulary(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T20:12:58.468270Z",
     "start_time": "2019-07-14T20:12:49.224551Z"
    }
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(output_dir, num_labels=num_labels)\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T20:14:14.748958Z",
     "start_time": "2019-07-14T20:14:13.414774Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "eval_examples = processor.get_dev_examples(data_dir)\n",
    "cached_eval_features_file = os.path.join(data_dir, 'dev_{}_{}_{}'.format(list(filter(None, bert_model.split('/'))).pop(), str(max_seq_len), str(task_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T21:20:16.470348Z",
     "start_time": "2019-07-14T21:15:27.809922Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(cached_eval_features_file, 'rb') as reader:\n",
    "        eval_features = pickle.load(reader)\n",
    "except:\n",
    "    eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_len, tokenizer, 'classification')\n",
    "    with open(cached_eval_features_file, 'wb') as writer:\n",
    "        pickle.dump(eval_features, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T21:30:39.393252Z",
     "start_time": "2019-07-14T21:30:39.062956Z"
    }
   },
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "\n",
    "all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "\n",
    "eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-14T21:40:27.222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb10db8fa5f4856800b1f774ee83850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=1286, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_loss = 0\n",
    "nb_eval_steps =0 \n",
    "preds = []\n",
    "out_label_ids = None\n",
    "for input_ids, input_mask, segment_ids, label_ids in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    label_ids = label_ids.to(device)\n",
    "    \n",
    "    with torch.no_grad(): #do not compute gradients\n",
    "        logits = model(input_ids, token_type_ids = segment_ids, attention_mask = input_mask)\n",
    "    loss_fct = CrossEntropyLoss()\n",
    "    tmp_eval_loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "    \n",
    "    eval_loss += tmp_eval_loss.mean().item()\n",
    "    nb_eval_steps+=1\n",
    "    if len(preds) == 0:\n",
    "        preds.append(logits.detach().cpu().numpy())\n",
    "        out_label_ids = label_ids.detach().cpu().numpy()\n",
    "    else:\n",
    "        preds[0] = np.append(preds[0], logits.detach().cpu().numpy(), axis=0)\n",
    "        out_label_ids = np.append(out_label_ids, label_ids.detach().cpu().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T21:36:34.855438Z",
     "start_time": "2019-07-14T21:36:34.826454Z"
    }
   },
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-3d965ea1636f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0meval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnb_eval_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_label_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bert/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bert/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "eval_loss = eval_loss / nb_eval_steps\n",
    "\n",
    "preds = preds[0]\n",
    "preds = np.argmax(preds, axis=1)\n",
    "result = compute_metrics(task_name, preds, out_label_ids)\n",
    "loss= tr_loss/global_step \n",
    "result['eval_loss'] = eval_loss\n",
    "result['global_step'] = global_step\n",
    "result['loss'] = loss\n",
    "\n",
    "output_eval_file = os.path.join(output_dir, \"eval_results.txt\")\n",
    "with open(output_eval_file, 'w') as writer:\n",
    "    logger.info(\"***** Eval results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T21:36:39.815093Z",
     "start_time": "2019-07-14T21:36:39.809021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
