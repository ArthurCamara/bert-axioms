epochs:
  desc: Number of epochs to train over
  value: 3
tokenizer_class:
  desc: Class to be used on tokenizer
  value: "distilbert-base-uncased"
data_home:
  desc: Where to save data to
  value: "/ssd2/arthur/bert-axioms"
download_path:
  desc: Default msmarco download path
  value: "https://msmarco.blob.core.windows.net/msmarcoranking/"
logging_level:
  desc: Level for Python logger
  value: "INFO"
force_steps:
  desc: Steps to forecefully run
  value:
    -  None
#     -  dev_query_tokenizer
train_queries:
  desc: Number of train queries expected
  value: 367013
full_dev_queries:
  desc: Number of dev queries in the original dataset
  value: 5193
corpus_size:
  desc: Number of documents in the corpus
  value: 3213835
number_of_cpus:
  desc: Number of CPUs to be used on parallel bits
  value: 48
max_document_len:
  desc: Maximum number of tokens to be considered in the document for the cut-down version of the dataset
  value: 512